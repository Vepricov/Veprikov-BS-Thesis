\section{Введение}

Системы машинного обучения и принятия решений в масштабах общества, по определению, должны оказывать значительное влияние на общество в целом. Недавний анализ \cite{cais2023statementairisk} представляет широкий спектр потенциальных проблем и областей, вызывающих беспокойство, связанных с такими системами \cite{suresh2020misplaced}. Решение этих проблем и  аспекты разработки надежных систем \cite{li2023trustworthy} требуют различных методов проектирования алгоритмов машинного обучения и искусственного интеллекта, сочетающих формальное математическое моделирование, методы инженерии, основанные на данных и долгосрочный анализ рисков \cite{sifakis2023trustworthy, pei2022requirements, he2021challenges}. Одним из ключевых атрибутов качества заслуживающих доверия систем машинного обучения \cite{serban2021practices,toreini2020relationship,siebert2020towards} и социально ответственных алгоритмов ИИ (SRA)\cite{cheng2021socially} является их способность вести себя так, как ожидают пользователи, без каких-либо непредвиденных побочных эффектов.

Процесс \emph{многократного машинного обучения} описывает ситуацию в системе искусственного интеллекта, когда входные данные для алгоритма обучения могут частично зависеть от предыдущих предсказаний, сделанных системой. 

Методы машинного обучения обычно принимают определенные предположения о данных, например, данные должны быть н.о.р., или стационарными с белым шумом, или среда, в которой работает агент, остается неизменной, или существует дрейф данных, не зависящий от обучающегося алгоритма. Отличительная особенность процесса многократного обучения --- та, которая оправдывает введение названия, --- заключается в том, что состояние среды в процессе становится причинно-следственно зависимым от алгоритма обучения и выдаваемых прогнозов. 
    
При высокой степени автоматизации, то есть при высоком уровне использования предсказаний и жестком следовании им, возникает так называемая \emph{петля положительной обратной связи}. В результате этой петли алгоритм обучения повторно применяется к данным, содержащим предыдущие предсказания. Такое многократное обучение приводит к заметному непреднамеренному сдвигу в распределениях входных данных и предсказаний системы \citep{khritankov2023positive}. Таким образом, подобная система машинного обучения нарушает требования доверия, предъявляемые к социально ответственным алгоритмам искусственного интеллекта. 

Во многих случаях многократный процесс машинного обучения может представлять поведение системы, взаимодействующей со своими пользователями. Например, в системах, рекомендующих потребителям товары или прогнозирующих рыночные цены \cite{khritankov2021existence, sinha2016deconvolving} и обучающихся на основе ответов пользователей, системах поддержки принятия решений в здравоохранении \cite{adam2020hidden} и предиктивных системах охраны порядка и общественной безопасности \cite{ensign2018runaway}, которые вносят смещение в обучающие данные в результате непреднамеренной петли обратной связи.

Данная работа основывается да статье \Red{[prerint]}. Основные теоретические результаты были написаны Веприковым Андреем под руководством Хританкова Антона и Афанасьева Александра. Эксперименты основаны на коде из статьи Хританкова Антона \cite{khritankov2021hidden}, которые были переработаны для проверки результатов, полученных в данном исследовании.

Основным вкладом данной работы является модель динамических систем \cite{galor2007discrete} процесса многократного машинного обучения. Формально мы рассматриваем множество $\textbf{F}$ функций плотности вероятности (PDF), каждая из которых описывает данные, доступные системе машинного обучения на заданном временном шаге $t$. Затем мы вводим отображение $\text{D}_t$, которое действует на заданную функцию плотности $f_t \in \textbf{F}$ для получения нового распределения данных $f_{t+1}$. Общая модель изучаемого нами процесса может быть записана в виде

\begin{equation*}
        f_{t+1}(x) = \text{D}_t(f_t)(x),\, f_0(x)\, \text{известна}, t = \{0, 1, 2,...\}.
\end{equation*}

В этой модели отображение $\text{D}_t$ может включать следующие действия, выполняемые системой: семплирование обучающих данных из $f_t(x)$, обновление параметров модели, предоставление одного или нескольких прогнозов пользователям. В результате применения отображения $\text{D}_t$ получается новое распределение вероятностей с функцией плотности $f_{t+1}(x)$.

%%%% Related work %%%%

Приведем некоторые сведения о исследуемой проблеме. Во многих практических приложениях контекст, в котором используется система машинного обучения, может сам по себе изменять обучающие данные с течением времени. Такой \emph{дрейф данных} может быть вызван какими-то внешними факторами или порожден самой системой. Иллюстрацией этого может быть модель прогнозирования цен на жилье, которая опирается на фактические покупки, рекомендованные моделью \cite{khritankov2021hidden}. Таким образом, модель частично учится на своих собственных прогнозах. Примеры подобных эффектов, таких как эхо-камеры и пузыри-фильтров, широко описаны в литературе \cite{davies2018redefining, spohr2017fake, michiels2022filter, khritankov2021existence}. Энсин и др. \cite{ensign2018runaway} задокументировали эффект положительной петли обратной связи, когда система предиктивного полицейского контроля изменяет данные о происшествиях и вносит смещение в прогнозы. Семинар по проблемам справедливости в машинном обучении \cite{chouldechova2020snapshot} показал, что нерегулируемые скрытые петли обратной связи могут приводить к смещению решений, что делает их нежелательными эффектами.

В качестве еще одной иллюстрации многократного машинного обучения можно привести пример из \cite{taori2023data}. Если в обучающем наборе данных преобладают элементы определенного класса, то любой оптимальный байесовский классификатор будет предсказывать принадлежность новых объектов только к этому преобладающему классу. Это внесет смещение в набор данных. В работе \cite{adam2022error} исследуют, как петли обратной связи в системах машинного обучения влияют на алгоритмы классификации. Авторы описывают эффект \textit{усиления ошибки} в системе искусственного интеллекта в здравоохранении, который приводит к потере качества прогноза с течением времени из-за ошибок, допущенных ранее.

В статье \cite{khritankov2023positive} демонстрируется система машинного обучения, допускающая непреднамеренные петли обратной связи. Авторы доказывают достаточные условия для возникновения этих эффектов, а также предлагают процедуру измерения для оценки данных условий на практике. В данной работе используется другой подход.

Наша постановка задачи использует аппарат дискретных динамических систем \cite{galor2007discrete, sandefur1990discrete}. Этот раздел менее изучен, чем динамические системы с непрерывным временем \cite{katok1995introduction, nemytskii2015qualitative, pauline2022observer, ouannas2017simple}. Основные вопросы исследования дискретных динамических систем включают существование неподвижных точек для данной динамической системы \cite{milnor2018analytic}, поведение предела \cite{sharma2015uniform}, определение того, является ли конкретная траектория регулярной или хаотической \cite{zhang2006discrete}. 